#!/usr/bin/env python
# coding: utf-8

import streamlit as st
from PIL import Image
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import bokeh
from bokeh.plotting import figure
#import pickle
from sklearn.metrics import accuracy_score, auc, confusion_matrix, f1_score, precision_score, recall_score, roc_curve
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import multilabel_confusion_matrix, plot_confusion_matrix, classification_report
from imblearn.over_sampling import SMOTE

st.set_page_config( page_title="Incendios en Galicia",
                   #page_icon="游븱",
                   layout="wide",
                   initial_sidebar_state="expanded")



st.title('An치lisis y predicci칩n de incendios forestales en Galicia - SMOTE')
         
st.write('El presente proyecto tiene como objetivo el an치lisis de los incendios producidos en Galicia durante el periodo 2001 - 2015, ' +
         'as칤 como realizar predicciones de la CAUSA de incendios con las caracter칤sticas (datos) que el usuarios desea consultar.')
         

  
  
  
  
  

# Preprocesar el dataset (renombrar columnas, etc.)
url = 'https://raw.githubusercontent.com/LenaMorianu/ANALISIS-Y-PREDICCION-DE-LOS-INCENDIOS-FORESTALES-EN-GALICIA/main/Streamlit/dataset_modelo.csv'
df = pd.read_csv(url, encoding='ISO-8859-1')

df.drop(['Unnamed: 0'], axis=1, inplace=True)


df.rename(columns={'superficie':'Superficie_quemada',
                   'lat':'Latitud',
                   'lng':'Longitud',
                   'time_ctrl':'Tiempo_control',
                   'personal':'Personal',
                   'medios':'Medios',
                   'TMEDIA':'Temperatura_media',
                   'RACHA':'Racha',
                   'SOL':'Sol_horas',
                   'A츾췀o':'Ano',
                   'PRES_RANGE':'Presion',
                   'target':'Causa'}, inplace=True)

df.head()


st.write('')
st.write('')
st.write('')
st.write('El dataset de an치lisis')
st.write('')
st.table(df.head())  



############

#df_1 = df[df['Causa']==1].copy()
#df_1.reset_index(drop=True, inplace=True)

#df_resto = df[df['Causa']!=1].copy()
#df_resto.reset_index(drop=True, inplace=True)

#df_1_6 = df_1.iloc[5600:6720,:]


#df_prueba6 = pd.concat([df_1_6, df_resto])
#df_prueba6.reset_index(drop=True, inplace=True)

############


X_train, X_test, y_train, y_test = train_test_split (df.drop(['Causa'],axis=1), 
                                                     df.Causa , 
                                                     test_size = 0.3, 
                                                     random_state = 333, 
                                                     stratify = df.Causa)

oversample3 = SMOTE(random_state=19, sampling_strategy='all')
X_train_SMOTE, y_train_SMOTE = oversample3.fit_resample(X_train, y_train)


classifier = RandomForestClassifier(bootstrap = True, 
                                    criterion= 'entropy', 
                                    max_depth=None, 
                                    random_state = 13,
                                    n_estimators=150).fit(X_train_SMOTE, y_train_SMOTE)

classifier.score(X_test, y_test)

y_pred = classifier.predict(X_test)

LABELS=['Intencionado', 'Causa desconocida', 'Negligencia', 'Fuego reproducido', ' Rayo']

#st.write('CLASSIFICATION REPORT:')
st.write('')
#st.write(print(classification_report(y_test, y_pred)))

st.write("El TEST SCORING: {0:.2f} %".format(100 * classifier.score(X_test, y_test)))
#st.write("El TEST SCORING: {0:.2f} %".format(100 * modelo.score(X_test, y_test)))         

#st.table(plot_confusion_matrix(classifier, X_test, y_test, normalize='true'))

############

# Crear los dataset de TRAIN y TEST
#X_train, X_test, y_train, y_test = train_test_split(df.drop(['Causa'], axis = 1),
#                                                    df['Causa'],
#                                                    train_size   = 0.8,
#                                                    random_state = 1234,
#                                                    shuffle      = True,
#                                                    stratify = df['Causa'])



#modelo = RandomForestClassifier(bootstrap = True, 
#                                criterion= 'entropy', 
#                                max_depth=None, 
#                                n_estimators=150,
#                                class_weight='balanced').fit(X_train, y_train)



#st.write("El TEST SCORING: {0:.2f} %".format(100 * classifier.score(X_test, y_test)))
#st.write("El TEST SCORING: {0:.2f} %".format(100 * modelo.score(X_test, y_test)))         

#st.table(plot_confusion_matrix(modelo, X_test, y_test, normalize='true'))


st.write('')
st.write('')
st.write('')


#st.table(classification_report(y_test, y_pred))

# y_proba = pd.DataFrame(modelo.predict_proba(X_test))      
y_proba = pd.DataFrame(classifier.predict_proba(X_test))
y_proba.columns = y_proba.columns.map({0:'Intencionado',
                                       1:'Causa_desconocida',
                                       2:'Negligencia',
                                       3:'Fuego_reproducido',
                                       4:'Rayo'}).astype(str)

st.write('La probabilidad de cada observaci칩n de pertenecer a las categor칤as CAUSAS de incendio:')
st.write('')

y2 = y_proba.head(10)

st.table(y2)
  
  
  
  
#Variables de predicci칩n

st.sidebar.subheader('Valores para predicci칩n:')

var1 = st.sidebar.number_input('Superficie_quemada', min_value=0.00, max_value=10000.00, step=100.00)
var2 = st.sidebar.number_input('Tiempo_control', min_value=0.00, max_value=1000.00, step=50.00)
var3 = st.sidebar.number_input('Medios', min_value=0, max_value=50, step=5)
var4 = st.sidebar.number_input('Presion', min_value=0.00, max_value=15.00, step=1.00) 
var5 = st.sidebar.number_input('Sol_horas', min_value=0.00, max_value=1000.00, step=50.00)
var6 = st.sidebar.number_input('Personal', min_value=0, max_value=100, step=5)
var7 = st.sidebar.number_input('Racha', min_value=0.00, max_value=100.00, step=5.00)
var8 = st.sidebar.number_input('Longitud', min_value=-10.00, max_value=-6.00, step=0.05)
var9 = st.sidebar.number_input('Latitud', min_value=41.00, max_value=44.00, step=0.05)
var10 = st.sidebar.number_input('Ano', min_value=2001, max_value=2015, step=1)
var11 = st.sidebar.number_input('Temperatura_media', min_value=-30.00, max_value=50.00, step=5.00)


st.write('')

boton_prediccion = st.sidebar.button('REALIZAR PREDICCI칍N')


# Realizar la predicci칩n
if boton_prediccion:
  values =[var1,var2,var3,var4,var5,var6,var7,var8,var9,var10,var11]
  columnas = list(df.columns.drop(['Causa']))
  df_pred = pd.DataFrame(values, columnas)  
  pred = [list(df_pred[0])]
  #result = modelo.predict(pred)
  #prob = modelo.predict_proba(pred)       
  result = classifier.predict(pred)
  prob = classifier.predict_proba(pred)
  
  
  if result == 1: st.write('CAUSA incendio: **INTENCIONADO**')
  if result == 2: st.write('CAUSA incendio: **CAUSA DESCONOCIDA**')
  if result == 3: st.write('CAUSA incendio: **NEGLIGENCIA**')
  if result == 4: st.write('CAUSA incendio: **FUEGO REPRODUCIDO**')
  if result == 5: st.write('CAUSA incendio: **RAYO**')
  

  
st.sidebar.markdown('__________________________________________________________________________')  

#image = Image.open('./images/IMG2.png')
#st.image(image, caption='UCM')          
    
st.sidebar.write('')
st.sidebar.write('Universidad Complutense de Madrid')
st.sidebar.write('M츼STER BIG DATA & DATA SCIENCE')
st.sidebar.write('Madrid - Septiembre 2021')
st.sidebar.write('______________________________________________________________________')
st.sidebar.write('**AUTORES:**')
st.sidebar.markdown(' - Alejandra Garc칤a Mosquera')
st.sidebar.markdown(' - Jorge G칩mez Marco')
st.sidebar.markdown(' - Ana Hern치ndez Villate')
st.sidebar.markdown(' - Alex Ilundain')
st.sidebar.markdown(' - Alicia Mar칤a L칩pez Machado')
st.sidebar.markdown(' - Lena Morianu')
 
  
  
  
# Preguntar por el tama침o del dataset de TEST
#test_size = st.sidebar.slider(label = 'Elige el tama침o del dataset de TEST (%):',
#                              min_value=0,
#                              max_value=100,
#                              value=15,
#                              step=1)


